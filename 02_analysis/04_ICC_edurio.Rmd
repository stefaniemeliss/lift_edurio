---
title: "Edurio data: Intraclass correlation coefficients (ICC)"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---

The intraclass correlation coefficient (ICC) is a key descriptive statistic in clustered survey analysis that quantifies the similarity or relatedness of observations within clusters relative to between clusters. It is defined as the ratio of between-cluster variance to the total variance (sum of between-cluster and within-cluster variances). The ICC ranges from 0 to 1, where an ICC of 0 indicates no correlation of outcomes within clusters (i.e., observations within clusters are no more similar to each other than to those in other clusters), and an ICC close to 1 means outcomes within a cluster are highly similar or identical.

In clustered surveys or cluster-randomized trials, where groups (clusters) rather than individuals are randomized or sampled, the ICC is crucial because it affects the effective sample size and the statistical power of study designs. A high ICC implies greater similarity within clusters, reducing the effective sample size towards the number of clusters rather than the total number of individuals, as within-cluster observations add less independent information. Conversely, a low ICC indicates more independent observations across the sample.

The ICC typically takes values less than 0.2 in pragmatic cluster trials, often around 0.01 to 0.05 in human studies. It is used to calculate the design effect, which adjusts for the loss of independence among observations within clusters when determining sample size requirements. This makes sample size calculations and power analyses in clustered designs dependent on prior estimates or pilot data of the ICC.

In educational research and survey sampling contexts, ICC values help guide efficient sampling strategies: lower ICC values suggest sampling more individuals within fewer clusters, whereas higher ICC values call for sampling more clusters with fewer individuals each. Estimation of ICC often uses intercept-only multilevel regression models to partition variance components.

Overall, the ICC informs how clustering impacts data analysis and design, ensuring accurate inference by accounting for within-cluster correlations in survey or trial data analysis.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#### SETUPS ####
source(file = list.files(path = "..", pattern = "setup.R", recursive = T, full.names = T))
library(psych)
library(kableExtra)
library(lme4)

# read in data
df <- read.csv(file = file.path(dir_data, "data_edurio.csv"))

df <- df %>%
  mutate(
    # for mixed-effects models in R, the grouping variable should be a factor
    establishmentname = as.factor(establishmentname),
    academic_year = as.factor(academic_year),
    # apply min-max scaling to harmonise inconsistent response scales
    q_rec_work = 
      ifelse(year == 2018, (q_job_01_ans - 0) / (10 - 0),
             ifelse(year != 2018, (q_job_01_ans - 1) / (10 - 1),
                         NA)),
    # re-code resign variable, so that smaller numbers means less considerations of resigning
    q_resign_freq = 6 - q_job_03_ans,
    # re-code variable on resign considerations to retention at school level
    q_ret_school = ifelse(q_resign_freq < 3, 1, # never or rarely
                        ifelse(q_resign_freq >= 3, 0, NA)), # sometimes, often or constantly
    # re-code school-level leavers to retention at sector level
    q_ret_sect = ifelse(q_job_04_txt == "Remain in the profession", 1,
                        ifelse(q_job_04_txt == "Leave the profession", 0, NA))
    )
```

```{r icc_cont, echo=FALSE, eval=F}
### ICC for continuous outcomes - school intercept ####

# Fit a null (intercept-only) mixed-effects model #

# "random intercept model" or an "intercept-only multilevel model."
# partitions the variance of factor_score into between-school variance (random intercept variance) and within-school variance (residual variance)

# df[, dv] ~ 1 means model includes only an intercept as a fixed effect. This intercept represents the overall average factor score across all teachers, ignoring any predictors.
# (1 | df[, grp]) specifies a random intercept for each school
# model estimates a separate intercept for each school, allowing the average factor score to vary between schools while assuming the same slope (if any predictors were included) across schools. This captures the clustering structure by letting each school have its own baseline mean deviation from the overall intercept.
# use Restricted Maximum Likelihood (REML) estimation to estimate the variance components
# REML = TRUE helps produce unbiased and reliable estimates of the variance components
model <- lmer(df[, dv] ~ 1 + (1 | df[, grp]), REML = TRUE)

# Extract variance components # 

# VarCorr(model) returns an object containing the variance-covariance components of the random effects in the model. 
# This typically includes the variances for each random intercept or slope term.
variance_components <- as.data.frame(VarCorr(model))

# variance_components$vcov contains the numerical variance or covariance estimates
# variance_components$grp identifies the grouping factor (random effect) to which each variance component belongs; here, it labels which rows correspond to which random effect grouping for each school.
# variance_components$vcov[variance_components$grp == "df[, grp]"] selects the variance component(s) specifically for the random intercept associated with the grouping factor "establishmentname" - this is the between-school variance
var_betw <- variance_components$vcov[variance_components$grp == "df[, grp]"]

# VarCorr object has an attribute called "sc" which stands for the residual standard deviation (also called the scale parameter). 
# This represents the estimated standard deviation of the residual errors â€” the variation in the outcome not explained by the random effects.
# Squaring the residual DD with ^2 converts it to the residual variance
# Residual variance = within-cluster variance component, i.e., variation among individuals within the same cluster
var_with <- attr(VarCorr(model), "sc")^2

# Calculate ICC # 

# ICC = proportion of total variance attributable to differences between clusters
# ICC quantifies the degree to which observations within the same cluster resemble each other compared to observations in different clusters.
# An ICC closer to 1 means high similarity within clusters, while an ICC near 0 means little to no clustering effect
ICC <- var_betw / (var_betw + var_with)
cat("ICC (school as random intercept): ", round(ICC, 3), "\n\n", sep = "")

### ICC for continuous outcomes - year intercept ####

# Fit a linear mixed model with random intercepts for schools and years #
model <- lmer(df[, dv] ~ 1 + (1 | df[, yr]), REML = TRUE)

# Extract variance components #
variance_components <- as.data.frame(VarCorr(model))
var_betw <- variance_components$vcov[variance_components$grp == "df[, yr]"]
var_with <- attr(VarCorr(model), "sc")^2

# Calculate ICC #
ICC <- var_betw / (var_betw + var_with)
cat("ICC (years as random intercept): ", round(ICC, 3), "\n\n", sep = "")

### ICC for continuous outcomes - school and year intercept ####

# Fit a linear mixed model with random intercepts for schools and years #
model <- lmer(df[, dv] ~ 1 + (1 | df[, grp]) + (1 | df[, yr]), REML = TRUE)

# Extract variance components #
variance_components <- as.data.frame(VarCorr(model))
var_school <- variance_components$vcov[variance_components$grp == "df[, grp]"]
var_year <- variance_components$vcov[variance_components$grp == "df[, yr]"]
var_res <- attr(VarCorr(model), "sc")^2
var_total = var_school + var_year + var_res

# Calculate ICC #
ICC_school = var_school / var_total
ICC_year = var_year / var_total
cat("ICC[school] (school and years as random intercepts): ", round(ICC_school, 3), "\n\n", sep = "")
cat("ICC[year] (school and years as random intercepts): ", round(ICC_year, 3), "\n\n", sep = "")

```

```{r icc_bin, echo=FALSE, eval=F}
### ICC for binary outcomes - school intercept ####

# Fit a null (intercept-only) logistic mixed-effects model
# use glmer for generalised models and family = binomial
# remove missing data
model <- glmer(df[!is.na(df[, dv]), dv] ~ 1 + (1 | df[!is.na(df[, dv]), grp]), family = binomial)

# Extract the between-cluster variance (random intercept variance)
variance_components <- as.data.frame(VarCorr(model))
var_betw <- variance_components$vcov[variance_components$grp == "df[!is.na(df[, dv]), grp]"]

# The residual variance for logistic models is fixed at pi^2 / 3 (~3.29)
var_res <- (pi^2) / 3

# Calculate ICC
ICC <- var_betw / (var_betw + var_res)
cat("ICC (school as random intercept): ", round(ICC, 3), "\n\n", sep = "")

### ICC for binary outcomes - year intercept ####

# Fit a null (intercept-only) logistic mixed-effects model
model <- glmer(df[!is.na(df[, dv]), dv] ~ 1 + (1 | df[!is.na(df[, dv]), yr]), family = binomial)

# Extract the between-cluster variance (random intercept variance)
variance_components <- as.data.frame(VarCorr(model))
var_betw <- variance_components$vcov[variance_components$grp == "df[!is.na(df[, dv]), yr]"]

# The residual variance for logistic models is fixed at pi^2 / 3 (~3.29)
var_res <- (pi^2) / 3

# Calculate ICC
ICC <- var_betw / (var_betw + var_res)
cat("ICC (year as random intercept): ", round(ICC, 3), "\n\n", sep = "")

### ICC for binary outcomes - school and year intercept ####

# Fit a null (intercept-only) logistic mixed-effects model
model <- glmer(df[!is.na(df[, dv]), dv] ~ 1 + (1 | df[!is.na(df[, dv]), grp]) + (1 | df[!is.na(df[, dv]), yr]), family = binomial)

# Extract variance components #
variance_components <- as.data.frame(VarCorr(model))
var_school <- variance_components$vcov[variance_components$grp == "df[!is.na(df[, dv]), grp]"]
var_year <- variance_components$vcov[variance_components$grp == "df[!is.na(df[, dv]), yr]"]
var_res <- attr(VarCorr(model), "sc")^2
var_total = var_school + var_year + var_res

# Calculate ICC #
ICC_school = var_school / var_total
ICC_year = var_year / var_total
cat("ICC[school] (school and years as random intercepts): ", round(ICC_school, 3), "\n\n", sep = "")
cat("ICC[year] (school and years as random intercepts): ", round(ICC_year, 3), "\n\n", sep = "")
```



```{r, echo = F, results='asis',fig.align='center', warning=FALSE}
grp = "establishmentname"
yr = "academic_year"

scores <- c("f_lead", "f_supp", "f_beh", "f_opp", "q_rec_work", "q_resign_freq")
# run ICC for continuous outcomes
for (dv in scores) {
  cat("###", dv, "\n\n")
<<icc_cont>>
}

scores <- c("q_ret_school", "q_ret_sect")
# run ICC for binary outcomes
for (dv in scores) {
  cat("###", dv, "(binary outcome)\n\n")
<<icc_bin>>
}

```

> Based on the ICC values, any teacher-level analysis will model random intercepts for schools and academic years.
